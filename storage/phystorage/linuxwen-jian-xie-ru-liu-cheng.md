![](/assets/storage-virutal-linuxfile1.png)上图是 Linux 写文件的一个流程图，图中主要包含三块，用户层、内核层、硬件层，Linux 在写文件时要经过系统调用、VFS、PageCache、文件系统、通用块管理层、IO调度层等多个流程后最终会将文件写入到磁盘中。而 blkio cgroup 作用在通用块管理层。Buffered I/O 是先写入到 PageCache 再走后面的流程将数据写入磁盘，而 Direct I/O 会绕过 PageCache 直接走后面的流程。

Linux 中应用程序对文件读写时默认是以 Buffered I/O 的形式写入的，此时并不需要经过通用块管理层，只需写入到 PageCache 即可，所以无法被限速，但 PageCache 中的数据总是要经过通用块管理层写入到磁盘的，原则上说也有影响，但是对于应用程序来说感受可能不一样，这与 PageCache 写入磁盘的机制也有关系。

在一般 I/O 的情况下，应用程序很可能很快的就写完了数据（在数据量小于缓存空间的情况下），然后去做其他事情了。这时应用程序感受不到自己被限速了，而内核在将数据从 PageCache 同步到磁盘阶段，由于 PageCache 中没有具体 cgroup 关联信息，所以所有 PageCache 的回写只能放到 cgroup 的 root 组中进行限制，而不能在其他cgroup 中进行限制，root cgroup 一般也是不做限制的。而在Direct IO的情况下，由于应用程序写的数据是不经过缓存层的，所以能直接感受到速度被限制，一定要等到整个数据按限制好的速度写完或者读完，才能返回。这就是当前 cgroup 的 blkio 限制所能起作用的环境限制。

PageCache 写入磁盘的机制：

（1）脏页太多，Page Cache 中的脏页比例达到一定阈值时回写，主要有下面两个参数来控制脏页比例：

* **dirty\_background\_ratio**
   表示当脏页占总内存的的百分比超过这个值时，后台线程开始刷新脏页。这个值如果设置得太小，可能不能很好地利用内存加速文件操作。如果设置得太大，则会周期性地出现一个写 I/O 的峰值，默认为 10；
* **dirty\_background\_bytes**
  ：和 
  **dirty\_background\_ratio**
   实现相同的功能，该参数依据脏页字节数来判断，但两个参数只会有其中一个生效，默认为 0；
* **dirty\_ratio**
   当脏页占用的内存百分比超过此值时，内核会阻塞掉写操作，并开始刷新脏页，默认为 20；
* **dirty\_bytes**
  ：和参数 
  **dirty\_ratio**
   实现相同功能，该参数依据脏页字节数来判断，但两个参数只会有其中一个生效，默认为 0；

（2）脏页存在太久，内核线程会周期性回写，脏页存在时间主要由以下几个参数控制：

* **dirty\_writeback\_centisecs**
   表示多久唤醒一次刷新脏页的后台线程，这个参数会和参数 
  **dirty\_background\_ratio**
   一起来作用，一个表示大小比例，一个表示时间；即满足其中任何一个的条件都达到刷盘的条件，默认为 500；
* **dirty\_expire\_centisecs**
   表示脏页超过多长时间就会被内核线程认为需要写回到磁盘，默认为 3000；



