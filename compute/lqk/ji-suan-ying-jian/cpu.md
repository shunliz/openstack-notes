DPU（ Data Processing Unit，数据处理器）是针对数据处理和以数据为中心的计算模型设计的硬件加速器。与 CPU 和 GPU 等其他硬件加速器不同，DPU 使用MIMD架构，支持大规模并行处理。

许多企业将 DPU 用于人工智能和大数据等超级计算业务。通过阅读本文可以了解 DPU 的作用与优缺点，以帮助企业选择是否需要在其数据中心中使用 DPU。

DPU 本质上是为处理数据中心传输的数据而设计的。它专注于数据传输、数据缩减、数据安全，支持数据分析、加密和压缩。DPU 支持更高效的数据存储，从而能够释放 CPU 资源，让 CPU 专注于应用程序处理。

DPU 承担了 CPU 的网络和通信工作负载。它将处理器内核、硬件加速器和高性能网络接口相结合，能够处理大规模的工作负载。这种架构的实现使 DPU 能够确保正确的数据以正确的格式快速到达正确的位置。

当把 DPU 置于以数据为中心的基础架构的核心时，DPU 还可以解决服务器节点效率低下的问题。它可以缓解数据蔓延，提供高可用性和可靠性，并确保大规模数据的快速可访问性和可共享性。DPU 可以用于云计算数据中心或驱动复杂AI、ML\[3\]‍和深度学习算法的超级计算机。

简单来说，DPU 是一种具有硬件加速功能的可编程设备，它包含三个关键要素：

1. 一种行业标准、高性能、软件可编程的多核 CPU，通常基于广泛使用的 Arm 架构，与其他 SoC（System-on-a-chip，片上系统）组件紧密耦合。
2. 一种高性能网络接口，能够以线速或网络其余部分的速度解析、处理和有效地将数据传输到 GPU 和 CPU。
3. 一套丰富的灵活且可编程的加速引擎，可提高人工智能和机器学习、安全和存储等应用程序的性能。



STH（ServeTheHome） 尝试将 SmartNIC、DPU 和 Exotic NIC（基于 FPGA 的解决方案）进行了分类：  
![](/assets/微信图片_20220925012417.png)

可以划归到 DPU 分类的产品有：

* **NVIDIA BlueField-2：**
  是一个高度集成的 DPU，集成 ConnectX-6 DX 网络适配器与 ARM 处理器核阵列。BlueField-2 DPU通过 ASAP2的网络加速方案以及完整的数据面及控制面卸载，可以高效、高性能的支持虚拟化、裸金属、边缘计算场景的快速部署，通过 SNAP机制为存储提供完整的端到端解决方案。集成了各种安全加速，可以为数据中心提供隔离、安全性和加解密加速功能，它集成的 ARM Core 可以运行基础设施层的虚拟化、管理监控等功能。
* **NITRO 系统：**
  Nitro 系统用于为 AWS EC2 实例类型提供网络硬件卸载、EBS 存储硬件卸载、NVMe 本地存储、远程直接内存访问（RDMA）、裸金属实例的硬件保护/固件验证以及控制 EC2 实例所需的所有业务逻辑等。
* **Fungible DPU：**
  Fungible DPU 采用通用多线程处理器，结合标准以太网和 PCIe 接口。其他硬件组件包括高性能的片上 Fabric、定制的内存系统、一套完整的灵活数据加速器、可编程网络硬件流水线、可编程 PCIe 硬件流水线。
* **Pensando DPU：**
  包括网络功能（交换和路由、L3 ECMP、L4 负载均衡、Overlay 网络、VXLAN、IP-NAT等）、安全功能（微分段、DoS 保护、IPsec 终止、TLS/DTLS 终止等）以及存储功能（NVMe over TCP/RoCEv2、压缩/解压、加密/解密、SHA3 重复数据删除、CRC64/32 校验和等）。
* **Intel IPU：**
  IPU 使用专用协议加速器加速基础设施功能，包括存储虚拟化、网络虚拟化和安全性。允许灵活的工作负载放置来提高数据中心利用率。
* **Marvell DPU：**Marvell OCTEON 10 集成 ARM Neoverse N2 内核、1Tb 的交换机，支持内联加密，基于 VPP 的硬件加速器可将数据包处理速度提高多达 5 倍，基于机器学习的硬件加速引擎比软件处理性能提升 100 倍。



# **DPU 的应用场景**

DPU 承担了 CPU 的网络和通信工作负载，从而能够释放出 CPU 资源，让 CPU 专注于应用程序处理。DPU专注于以数据为中心的工作负载场景，例如数据传输、数据缩减、数据安全和分析。DPU 芯片采用特殊设计，将处理器内核与硬件加速器相结合。这种设计使 DPU 比 GPU 芯片更通用。DPU 拥有自己的专用操作系统，这意味着可以将其资源与主操作系统的资源结合起来，执行加密、纠删码、压缩或解压缩等功能。

云和超大规模提供商一直是这项技术的最早采用者。以下是 DPU 主要的应用场景：

## **网络数据路径加速引擎**

正常情况下，一个嵌入式 CPU对数据包的处理速度是无法超越独立 CPU 的。但如果网卡足够强大和灵活，能够处理所有网络中的数据，嵌入式 CPU 用来做控制路径的初始化和异常情况处理，这样就可以加速数据处理速度。

网络数据路径加速引擎至少需要具备以下功能：

* 像 OVS（开放式虚拟交换机）一样对数据包进行解析、匹配和处理。
* 基于 Zero Touch RoCE 的 RDMA 数据传输加速。
* 通过 GPU-Direct 加速器绕过 CPU，将来自存储和其他 GPU 的数据通过网络直接传给 GPU。
* TCP 通信加速，包括 RSS、LRO、checksum 等操作。
* 网络虚拟化的 VXLAN、 Geneve Overlay 和 VTEP offload。
* 面向多媒体流、CDN（内容分发网络）和新的 4K / 8K IP 视频（如基于 ST 2110 规范的 RiverMax）的 “Packet Pacing” 流量整形加速。
* 电信 Cloud RAN 的精准时钟加速器，例如 5T for 5G（精准时钟调度 5G 无线报文传输技术）功能。
* 在线 IPSEC 和 TLS 加密加速，但不影响其它正在运行的加速操作。
* 支持 SR-IOV、VirtIO 和 PV（Para-Virtualization）等虚拟化。
* 安全隔离：如信任根、安全启动、安全固件升级以及基于身份验证的容器和应用的生命周期管理等。

## **集成到 SmartNIC**

DPU 可以用作独立的嵌入式处理器，但通常是被集成到 SmartNIC（一种作为下一代服务器中关键组件的网卡）中使用。

### **助力数据中心存储**

可以使用 DPU 来支持数据中心的存储。例如，可以通过将 NVMe 存储设备连接到 DPU 的 PCIe 总线来加速对它们的访问。

DPU 还可实现更好地访问依赖 NVMe-oF 的远程存储设备。DPU 将这些远程存储设备作为标准 NVMe 设备呈现给系统。优化了与远程存储的连接，不再需要特殊的驱动程序来连接这些远程存储设备。

### **支撑以数据为中心的架构**





